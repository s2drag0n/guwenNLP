{"cells":[{"cell_type":"markdown","metadata":{"id":"TC3XqMsg7s9l"},"source":["### 导入所需的包"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69L93XNhuo1g","executionInfo":{"status":"ok","timestamp":1651909952403,"user_tz":-480,"elapsed":3318,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"}},"outputId":"c4beec47-9ff3-4d3a-ae8a-5de410db575c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3709,"status":"ok","timestamp":1651909956106,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"MfSREqZG6KvR","outputId":"7d9781e4-f3e1-4710-f021-c9a3e537fe81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}],"source":["!pip install transformers\n","import re\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import BertForTokenClassification, BertTokenizer\n","from transformers import AdamW\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from tqdm import tqdm, trange\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","metadata":{"id":"11NR8MwY704_"},"source":["### 导入训练好的模型"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":944,"status":"ok","timestamp":1651909957036,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"oEDvY-F86BDE"},"outputs":[],"source":["model=torch.load('/content/drive/MyDrive/finalModel')"]},{"cell_type":"markdown","metadata":{"id":"1yspuV0076JW"},"source":["### 数据清洗"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651909957037,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"tzhtir_R8Cz8"},"outputs":[],"source":["tag_to_ix = {\"D\": 0,\n","             \"P\": 1, \n","             \"j\": 2, \n","             \"M\": 3,\n","             \"B\": 4,\n","             \"E\": 5,\n","             \"0\": 6,\n","             \"[CLS]\": 7,\n","             \"[SEP]\": 8,\n","             \"[PAD]\": 9}\n","\n","ix_to_tag = {0: \"D\",\n","             1: \"P\",\n","             2: \"j\",\n","             3: \"M\",\n","             4: \"B\",\n","             5: \"E\",\n","             6: \"0\",\n","             7: \"[CLS]\",\n","             8: \"[SEP]\",\n","             9: \"[PAD]\"}"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":1595,"status":"ok","timestamp":1651909958627,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"17mcZLUR8Hk0"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(\"ethanyt/guwenbert-base\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1651909958629,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"CyjnXNidDo7I","outputId":"0412cd50-f2e5-4603-e1fd-7bb9fd6d2468"},"outputs":[{"output_type":"stream","name":"stdout","text":["Is CUDA available:  True\n","GPU numbers:  1\n","device_name:  Tesla K80\n"]}],"source":["print(\"Is CUDA available: \", torch.cuda.is_available())\n","n_gpu = torch.cuda.device_count()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"GPU numbers: \", n_gpu)\n","print(\"device_name: \", torch.cuda.get_device_name(0))"]},{"cell_type":"markdown","metadata":{"id":"FPu_rOx48kBt"},"source":["##### 输入文本"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651910792673,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"8IhsNAhl8cRr"},"outputs":[],"source":["# 先帝创业未半而中道崩殂，今天下三分，益州疲弊，此诚危急存亡之秋也。\n","# 然侍卫之臣不懈于内，忠志之士忘身于外者，盖追先帝之殊遇，欲报之于陛下也。\n","# text1 = \"告天即位高皇帝将登宝位先于前一年之十二月百官劝进时上御新宫拜词于天\"\n","# text2 = \"其略曰惟我中国自宋运告终帝命真人于沙漠入中国为天下主百有余年今运亦终\"\n","# 是时连阴，入明年元旦即晴。\n","# 至日，日光皎洁，合祭天地，上即位于南郊。\n","# 后值倾覆，受任于败军之际，奉命于危难之间，尔来二十有一年矣。\n","# 先帝知臣谨慎，故临崩寄臣以大事也。\n","# 李锜据浙西反，相者言于锜曰：“朱氏有奇相，当生天子。”\n","# 锜既死，后入掖庭，为郭太后侍儿。\n","# 至若春和景明，波澜不惊;上下天光，一碧万顷;沙鸥翔集，锦鳞游泳;岸芷汀兰，郁郁青青。\n","# 而或长烟一空，皓月千里，浮光耀金，静影沉壁。\n","import re\n","# wordsInput(\"至若春和景明，波澜不惊;上下天光，一碧万顷;沙鸥翔集，锦鳞游泳;岸芷汀兰，郁郁青青。\",\n","#            \"而或长烟一空，皓月千里，浮光耀金，静影沉壁。\")"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":1253,"status":"ok","timestamp":1651910910883,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"CdYazQ7582fz"},"outputs":[],"source":["def token_maker(text11, text22):\n","  tokenized_text1 = tokenizer.encode(text11, add_special_tokens=True)\n","  tokenized_text2 = tokenizer.encode(text22, add_special_tokens=True)\n","  tokenized_texts=[]\n","  tokenized_texts.append(tokenized_text1)\n","  tokenized_texts.append(tokenized_text2)\n","  MAX_LEN = 64\n","  for tokenized_text in tokenized_texts:\n","    for i in range(MAX_LEN-len(tokenized_text)):\n","      tokenized_text.append(1)\n","  input_ids = tokenized_texts\n","  input_ids = torch.tensor(input_ids)\n","  return input_ids,tokenized_texts"]},{"cell_type":"markdown","metadata":{"id":"ieaGgr_D-hOd"},"source":["#### 创建mask并预测"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":397,"status":"ok","timestamp":1651910956242,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"8uXuDNkD-b9q"},"outputs":[],"source":["def mask_maker(input_ids):\n","  attention_masks = []\n","  attention_masks = [[float(i != 1) for i in input_id] for input_id in input_ids]\n","  attention_masks = torch.tensor(attention_masks)\n","  return attention_masks\n","\n","def gpu_transfer(attention_masks, input_ids):\n","  attention_masks=attention_masks.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","  input_ids=input_ids.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n","  return input_ids,attention_masks\n","\n","def model_use(input_ids, attention_masks):\n","  outputs = model(input_ids=input_ids, \n","                  attention_mask=attention_masks,\n","                  token_type_ids=None,\n","                  position_ids=None)\n","\n","  scores = outputs[0].detach().cpu().numpy()\n","\n","  pred_flat1 = np.argmax(scores[0], axis=1).flatten()\n","  pred_flat2 = np.argmax(scores[1], axis=1).flatten()\n","  list = []\n","  list.append(pred_flat1)\n","  list.append(pred_flat2)\n","  return list"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1651912887082,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"},"user_tz":-480},"id":"QeknxHlSOPmP"},"outputs":[],"source":["def puc_adder(text1,text11,pred_flat1):\n","  print(\"原标点：\",end=\"\")\n","  print(text1)\n","  list_text1 = list(text11)\n","  flag = 0\n","  for i in range(len(text1)+1):\n","    if(pred_flat1[i] == 0):\n","      list_text1.insert(i+flag, \"，\")\n","      flag+=1\n","    elif(pred_flat1[i] == 1):\n","      list_text1.insert(i+flag, \"、\")\n","      flag+=1\n","    elif(pred_flat1[i] == 2):\n","      list_text1.insert(i+flag, \"。\")\n","      flag+=1\n","    elif(pred_flat1[i] == 3):\n","      list_text1.insert(i+flag, \"：\")\n","      flag+=1\n","    elif(pred_flat1[i] == 4):\n","      list_text1.insert(i+flag, \"：“\")\n","      flag+=1\n","    elif(pred_flat1[i] == 5):\n","      list_text1.insert(i+flag, \"。”\")\n","      flag+=1\n","  print(\"加标点：\",end=\"\")\n","  print(\"\".join(list_text1))"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"BT81YmghujPi","executionInfo":{"status":"ok","timestamp":1651912889614,"user_tz":-480,"elapsed":387,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b878f5c-b87b-474d-e1a4-bc8d366a256a"},"outputs":[{"output_type":"stream","name":"stdout","text":["原标点：庆历四年春，滕子京谪守巴陵郡。越明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\n","加标点：庆历四年春，滕子京谪守巴陵郡越，明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\n","原标点：俱予观夫巴陵胜状，在洞庭一湖。衔远山，吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\n","加标点：俱予观夫巴陵胜状，在洞庭一湖，衔远，山吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\n"]}],"source":["def puc(a, b):\n","  text1 = \"\"\n","  text2 = \"\"\n","  text11 = \"\"\n","  text22 = \"\"\n","  text1 = a\n","  text2 = b\n","  pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n","  text11 = re.sub(pattern, '', a)\n","  text22 = re.sub(pattern, '', b)\n","  input_idss,tokenized_texts = token_maker(text11, text22)\n","  attention_maskss = mask_maker(tokenized_texts)\n","  input_ids,attention_masks = gpu_transfer(attention_maskss, input_idss)\n","  pred_flat1 = model_use(input_ids, attention_masks)[0]\n","  pred_flat2 = model_use(input_ids, attention_masks)[1]\n","  puc_adder(text1, text11, pred_flat1)\n","  puc_adder(text2, text22, pred_flat2)\n","puc(\"庆历四年春，滕子京谪守巴陵郡。越明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\",\"俱予观夫巴陵胜状，在洞庭一湖。衔远山，吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\")"]},{"cell_type":"code","source":["prag = \"庆历四年春，滕子京谪守巴陵郡。越明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\\\n","俱予观夫巴陵胜状，在洞庭一湖。衔远山，吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\\\n","然则北通巫峡，南极潇湘，迁客骚人，多会于此，览物之情，得无异乎？\\\n","若夫淫雨霏霏，连月不开，阴风怒号，浊浪排空，日星隐曜，山岳潜形，商旅不行，樯倾楫摧，薄暮冥冥，虎啸猿啼。\\\n","登斯楼也，则有去国怀乡，忧谗畏讥，满目萧然，感极而悲者矣。\\\n","至若春和景明，波澜不惊，上下天光，一碧万顷，沙鸥翔集，锦鳞游泳，岸芷汀兰，郁郁青青。\\\n","而或长烟一空，皓月千里，浮光跃金，静影沉璧，渔歌互答，此乐何极！登斯楼也，则有心旷神怡，宠辱偕忘，把酒临风，其喜洋洋者矣。\\\n","嗟夫！予尝求古仁人之心，或异二者之为，何哉？不以物喜，不以己悲，居庙堂之高则忧其民，处江湖之远则忧其君。是进亦忧，退亦忧。\\\n","然则何时而乐耶？其必曰先天下之忧而忧，后天下之乐而乐乎！噫！微斯人，吾谁与归？时六年九月十五日。\"\n","\n","prag = prag.replace(\"？\", \"。\").replace(\"！\", \"。\").replace(\".\", \"。\").replace(\"。“\", \"。”\").replace(\"；\", \"，\").replace(\"”。\", \"。”\")\n","prag = re.sub(\"。”\", \"。”\\n\", prag)\n","parg = re.sub(\"。(?!”)\", \"。\\n\", prag)\n","list_prag = parg.splitlines(False)\n","step = 2\n","list__ = [list_prag[i:i+step] for i in range(0, len(list_prag), step)]\n","for pair in list__:\n","  if len(pair)==1:\n","    pair.append(\"\")\n","  puc(pair[0], pair[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RpvDFkYkyHA","executionInfo":{"status":"ok","timestamp":1651912892653,"user_tz":-480,"elapsed":819,"user":{"displayName":"s 2drag0n","userId":"08640809914710840475"}},"outputId":"03ca8f59-5e68-425f-c359-02876d6ae35b"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["原标点：庆历四年春，滕子京谪守巴陵郡。\n","加标点：庆历四年春，滕子京谪守巴陵郡。\n","原标点：越明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\n","加标点：越明年，政通人和，百废具兴，乃重修岳阳楼，增其旧制，刻唐贤今人诗赋于其上，属予作文以记之。\n","原标点：俱予观夫巴陵胜状，在洞庭一湖。\n","加标点：俱予观夫巴陵胜状，在洞庭一湖。\n","原标点：衔远山，吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\n","加标点：衔远山吞长江，浩浩汤汤，横无际涯，朝晖夕阴，气象万千，此则岳阳楼之大观也，前人之述备矣。\n","原标点：然则北通巫峡，南极潇湘，迁客骚人，多会于此，览物之情，得无异乎。\n","加标点：然则北通巫峡，南极潇湘，迁客骚人，多会于此，览物之情，得无异乎。\n","原标点：若夫淫雨霏霏，连月不开，阴风怒号，浊浪排空，日星隐曜，山岳潜形，商旅不行，樯倾楫摧，薄暮冥冥，虎啸猿啼。\n","加标点：若夫淫雨霏霏，连月不开，阴风怒号，浊浪排空，日星隐曜，山岳潜形，商旅不行，樯倾楫摧，薄暮冥冥，虎啸猿啼。\n","原标点：登斯楼也，则有去国怀乡，忧谗畏讥，满目萧然，感极而悲者矣。\n","加标点：登斯楼也，则有去国怀乡，忧谗畏讥，满目萧然，感极而悲者矣。\n","原标点：至若春和景明，波澜不惊，上下天光，一碧万顷，沙鸥翔集，锦鳞游泳，岸芷汀兰，郁郁青青。\n","加标点：至若春和景明，波澜不惊，上下天光，一碧万顷，沙鸥翔集，锦鳞游泳，岸芷汀兰，郁郁青青。\n","原标点：而或长烟一空，皓月千里，浮光跃金，静影沉璧，渔歌互答，此乐何极。\n","加标点：而或长烟一空，皓月千里，浮光跃金，静影沉璧，渔歌互答，此乐何极。\n","原标点：登斯楼也，则有心旷神怡，宠辱偕忘，把酒临风，其喜洋洋者矣。\n","加标点：登斯楼也，则有心旷神怡，宠辱偕忘，把酒临风，其喜洋洋者矣。\n","原标点：嗟夫。\n","加标点：嗟夫。\n","原标点：予尝求古仁人之心，或异二者之为，何哉。\n","加标点：予尝求古仁人之心，或异二者之为，何哉。\n","原标点：不以物喜，不以己悲，居庙堂之高则忧其民，处江湖之远则忧其君。\n","加标点：不以物喜，不以己悲，居庙堂之高，则忧其民，处江湖之远，则忧其君。\n","原标点：是进亦忧，退亦忧。\n","加标点：是进亦忧，退亦忧。\n","原标点：然则何时而乐耶。\n","加标点：然则何时而乐耶。\n","原标点：其必曰先天下之忧而忧，后天下之乐而乐乎。\n","加标点：其必曰先天下之忧而忧，后天下之乐而乐乎。\n","原标点：噫。\n","加标点：噫。\n","原标点：微斯人，吾谁与归。\n","加标点：微斯人，吾谁与归。\n","原标点：时六年九月十五日。\n","加标点：时六年九月十五日。\n","原标点：\n","加标点：\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"modle调用.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}